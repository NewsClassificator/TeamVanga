{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjbWdLmkaMTU",
        "outputId": "218cca7d-f9e4-4bab-ed65-bbb0b9ef68f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.4.6)\n",
            "Requirement already satisfied: dataset in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.2)\n",
            "Requirement already satisfied: transformers in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.1)\n",
            "Requirement already satisfied: accelerate in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.11.0)\n",
            "Requirement already satisfied: spacy in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.8)\n",
            "Collecting kagglehub\n",
            "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (2.3.4)\n",
            "Requirement already satisfied: dill in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (0.4.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (0.70.18)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\slesa\\appdata\\roaming\\python\\python313\\site-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataset) (1.4.54)\n",
            "Requirement already satisfied: alembic>=0.6.2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataset) (1.17.1)\n",
            "Requirement already satisfied: banal>=1.0.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataset) (1.0.6)\n",
            "Requirement already satisfied: filelock in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\slesa\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (7.1.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (2.9.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (8.3.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.12.4)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (80.9.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from alembic>=0.6.2->dataset) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from alembic>=0.6.2->dataset) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: anyio in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.2.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\slesa\\appdata\\roaming\\python\\python313\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\slesa\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\slesa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
            "Installing collected packages: kagglehub\n",
            "Successfully installed kagglehub-0.3.13\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install evaluate dataset transformers datasets accelerate spacy kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnPu1TbadyHQ",
        "outputId": "a164745c-c588-4af0-d58f-be80d82f8c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "     ---------------------------------------- 0.0/400.7 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/400.7 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.5/400.7 MB 3.3 MB/s eta 0:02:03\n",
            "     --------------------------------------- 3.4/400.7 MB 10.2 MB/s eta 0:00:39\n",
            "     - ------------------------------------ 11.5/400.7 MB 21.6 MB/s eta 0:00:19\n",
            "     - ------------------------------------ 18.6/400.7 MB 25.7 MB/s eta 0:00:15\n",
            "     -- ----------------------------------- 27.5/400.7 MB 28.8 MB/s eta 0:00:13\n",
            "     --- ---------------------------------- 34.9/400.7 MB 30.0 MB/s eta 0:00:13\n",
            "     ---- --------------------------------- 42.2/400.7 MB 31.2 MB/s eta 0:00:12\n",
            "     ---- --------------------------------- 50.9/400.7 MB 32.1 MB/s eta 0:00:11\n",
            "     ----- -------------------------------- 55.6/400.7 MB 31.0 MB/s eta 0:00:12\n",
            "     ----- -------------------------------- 58.2/400.7 MB 31.2 MB/s eta 0:00:11\n",
            "     ----- -------------------------------- 58.5/400.7 MB 27.8 MB/s eta 0:00:13\n",
            "     ----- -------------------------------- 60.0/400.7 MB 24.8 MB/s eta 0:00:14\n",
            "     ------ ------------------------------- 66.1/400.7 MB 24.9 MB/s eta 0:00:14\n",
            "     ------ ------------------------------- 73.7/400.7 MB 26.0 MB/s eta 0:00:13\n",
            "     ------- ------------------------------ 82.3/400.7 MB 26.9 MB/s eta 0:00:12\n",
            "     -------- ----------------------------- 91.0/400.7 MB 27.6 MB/s eta 0:00:12\n",
            "     --------- ---------------------------- 96.7/400.7 MB 28.0 MB/s eta 0:00:11\n",
            "     --------- --------------------------- 104.9/400.7 MB 28.5 MB/s eta 0:00:11\n",
            "     ---------- -------------------------- 109.6/400.7 MB 28.0 MB/s eta 0:00:11\n",
            "     ---------- -------------------------- 114.0/400.7 MB 27.8 MB/s eta 0:00:11\n",
            "     ---------- -------------------------- 118.8/400.7 MB 27.8 MB/s eta 0:00:11\n",
            "     ----------- ------------------------- 124.5/400.7 MB 27.6 MB/s eta 0:00:10\n",
            "     ----------- ------------------------- 129.0/400.7 MB 27.1 MB/s eta 0:00:11\n",
            "     ------------ ------------------------ 136.8/400.7 MB 27.5 MB/s eta 0:00:10\n",
            "     ------------ ------------------------ 139.7/400.7 MB 27.2 MB/s eta 0:00:10\n",
            "     ------------- ----------------------- 145.5/400.7 MB 26.9 MB/s eta 0:00:10\n",
            "     -------------- ---------------------- 152.8/400.7 MB 27.2 MB/s eta 0:00:10\n",
            "     -------------- ---------------------- 155.2/400.7 MB 26.7 MB/s eta 0:00:10\n",
            "     -------------- ---------------------- 160.2/400.7 MB 26.5 MB/s eta 0:00:10\n",
            "     --------------- --------------------- 167.8/400.7 MB 26.8 MB/s eta 0:00:09\n",
            "     --------------- --------------------- 172.8/400.7 MB 26.7 MB/s eta 0:00:09\n",
            "     ---------------- -------------------- 178.8/400.7 MB 26.7 MB/s eta 0:00:09\n",
            "     ---------------- -------------------- 183.5/400.7 MB 26.9 MB/s eta 0:00:09\n",
            "     ----------------- ------------------- 187.2/400.7 MB 26.4 MB/s eta 0:00:09\n",
            "     ----------------- ------------------- 194.8/400.7 MB 26.6 MB/s eta 0:00:08\n",
            "     ------------------ ------------------ 199.0/400.7 MB 26.5 MB/s eta 0:00:08\n",
            "     ------------------ ------------------ 203.2/400.7 MB 26.2 MB/s eta 0:00:08\n",
            "     ------------------- ----------------- 210.2/400.7 MB 26.5 MB/s eta 0:00:08\n",
            "     ------------------- ----------------- 213.4/400.7 MB 26.2 MB/s eta 0:00:08\n",
            "     -------------------- ---------------- 221.5/400.7 MB 26.4 MB/s eta 0:00:07\n",
            "     -------------------- ---------------- 224.9/400.7 MB 26.2 MB/s eta 0:00:07\n",
            "     --------------------- --------------- 232.5/400.7 MB 26.3 MB/s eta 0:00:07\n",
            "     --------------------- --------------- 233.8/400.7 MB 25.9 MB/s eta 0:00:07\n",
            "     --------------------- --------------- 238.0/400.7 MB 25.7 MB/s eta 0:00:07\n",
            "     ---------------------- -------------- 245.1/400.7 MB 25.9 MB/s eta 0:00:07\n",
            "     ----------------------- ------------- 252.7/400.7 MB 26.1 MB/s eta 0:00:06\n",
            "     ----------------------- ------------- 256.6/400.7 MB 26.2 MB/s eta 0:00:06\n",
            "     ------------------------ ------------ 262.9/400.7 MB 26.3 MB/s eta 0:00:06\n",
            "     ------------------------ ------------ 266.6/400.7 MB 26.6 MB/s eta 0:00:06\n",
            "     ------------------------ ------------ 266.6/400.7 MB 26.6 MB/s eta 0:00:06\n",
            "     ------------------------- ----------- 274.2/400.7 MB 25.7 MB/s eta 0:00:05\n",
            "     ------------------------- ----------- 281.5/400.7 MB 25.7 MB/s eta 0:00:05\n",
            "     -------------------------- ---------- 289.7/400.7 MB 25.7 MB/s eta 0:00:05\n",
            "     --------------------------- --------- 297.0/400.7 MB 25.7 MB/s eta 0:00:05\n",
            "     --------------------------- --------- 300.9/400.7 MB 25.4 MB/s eta 0:00:04\n",
            "     ---------------------------- -------- 307.2/400.7 MB 25.3 MB/s eta 0:00:04\n",
            "     ---------------------------- -------- 311.7/400.7 MB 25.3 MB/s eta 0:00:04\n",
            "     ---------------------------- -------- 313.5/400.7 MB 25.0 MB/s eta 0:00:04\n",
            "     ----------------------------- ------- 319.3/400.7 MB 24.7 MB/s eta 0:00:04\n",
            "     ------------------------------ ------ 326.6/400.7 MB 26.0 MB/s eta 0:00:03\n",
            "     ------------------------------ ------ 334.2/400.7 MB 26.1 MB/s eta 0:00:03\n",
            "     ------------------------------- ----- 338.2/400.7 MB 25.8 MB/s eta 0:00:03\n",
            "     ------------------------------- ----- 343.9/400.7 MB 25.6 MB/s eta 0:00:03\n",
            "     -------------------------------- ---- 350.0/400.7 MB 25.6 MB/s eta 0:00:02\n",
            "     -------------------------------- ---- 352.8/400.7 MB 25.1 MB/s eta 0:00:02\n",
            "     --------------------------------- --- 359.9/400.7 MB 25.1 MB/s eta 0:00:02\n",
            "     --------------------------------- --- 366.5/400.7 MB 25.1 MB/s eta 0:00:02\n",
            "     ---------------------------------- -- 369.9/400.7 MB 24.9 MB/s eta 0:00:02\n",
            "     ---------------------------------- -- 377.5/400.7 MB 25.2 MB/s eta 0:00:01\n",
            "     ----------------------------------- - 381.2/400.7 MB 25.2 MB/s eta 0:00:01\n",
            "     ----------------------------------- - 387.7/400.7 MB 25.3 MB/s eta 0:00:01\n",
            "     ------------------------------------  390.6/400.7 MB 25.1 MB/s eta 0:00:01\n",
            "     ------------------------------------  397.4/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------  400.6/400.7 MB 24.9 MB/s eta 0:00:01\n",
            "     ------------------------------------- 400.7/400.7 MB 22.0 MB/s eta 0:00:00\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "import spacy\n",
        "import string\n",
        "!python -m spacy download en_core_web_lg\n",
        "import en_core_web_lg\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GJpX3QRaYxq",
        "outputId": "505564b3-55dd-45bf-ca3c-5532c699c696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/anzerone/clickbait-titles-ru?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113k/113k [00:00<00:00, 521kB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: C:\\Users\\slesa\\.cache\\kagglehub\\datasets\\anzerone\\clickbait-titles-ru\\versions\\1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"anzerone/clickbait-titles-ru\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4wNSCZAnafej",
        "outputId": "774f88c1-3c30-4acc-bb33-c3ada1cb89ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Родственник раскрыл настоящую фамилию Пугачёво...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Предсказания Матроны Московской на 2024-й год:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Пророчество схимонахини Нины об антихристе, ми...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>«Думал об этом»: что Путин сказал о своем прее...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Путин поручил уведомить россиян об изменениях ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3193</th>\n",
              "      <td>Путин поручил передать Республике Крым все акц...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3194</th>\n",
              "      <td>ЕК изучит просьбу Венгрии по нарушению Болгари...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>Глава \"Россетей\" доложил Путину о достижении ц...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>Платформа \"Мой экспорт\" научит устанавливать д...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>В Татарстане открыли завод по выпуску материнс...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3198 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     Родственник раскрыл настоящую фамилию Пугачёво...      1\n",
              "1     Предсказания Матроны Московской на 2024-й год:...      1\n",
              "2     Пророчество схимонахини Нины об антихристе, ми...      1\n",
              "3     «Думал об этом»: что Путин сказал о своем прее...      1\n",
              "4     Путин поручил уведомить россиян об изменениях ...      1\n",
              "...                                                 ...    ...\n",
              "3193  Путин поручил передать Республике Крым все акц...      0\n",
              "3194  ЕК изучит просьбу Венгрии по нарушению Болгари...      0\n",
              "3195  Глава \"Россетей\" доложил Путину о достижении ц...      0\n",
              "3196  Платформа \"Мой экспорт\" научит устанавливать д...      0\n",
              "3197  В Татарстане открыли завод по выпуску материнс...      0\n",
              "\n",
              "[3198 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('C:/Users/slesa/.cache/kagglehub/datasets/anzerone/clickbait-titles-ru/versions/1/titles_data.csv', delimiter = ';')\n",
        "df.columns = ['text', 'label']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cpMHX70KbEBs"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "punctuations = string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n8X3pSc-bJ9T"
      },
      "outputs": [],
      "source": [
        "def spacy_tokenizer(text):\n",
        "    doc = nlp(text)\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "    text = \" \".join(mytokens)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "U0rDmRvhbLXx",
        "outputId": "5efaf860-c9e2-477a-bd9f-7ab76ed97159"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>родственник раскрыл настоящую фамилию пугачёво...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>предсказания матроны московской на 2024 й год ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>пророчество схимонахини нины об антихристе мир...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>« думал об этом » что путин сказал о своем пре...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>путин поручил уведомить россиян об изменениях ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3193</th>\n",
              "      <td>путин поручил передать республике крым все акц...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3194</th>\n",
              "      <td>ек изучит просьбу венгрии по нарушению болгари...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3195</th>\n",
              "      <td>глава россетей доложил путину о достижении цел...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>платформа мой экспорт научит устанавливать дел...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>в татарстане открыли завод по выпуску материнс...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3198 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     родственник раскрыл настоящую фамилию пугачёво...      1\n",
              "1     предсказания матроны московской на 2024 й год ...      1\n",
              "2     пророчество схимонахини нины об антихристе мир...      1\n",
              "3     « думал об этом » что путин сказал о своем пре...      1\n",
              "4     путин поручил уведомить россиян об изменениях ...      1\n",
              "...                                                 ...    ...\n",
              "3193  путин поручил передать республике крым все акц...      0\n",
              "3194  ек изучит просьбу венгрии по нарушению болгари...      0\n",
              "3195  глава россетей доложил путину о достижении цел...      0\n",
              "3196  платформа мой экспорт научит устанавливать дел...      0\n",
              "3197  в татарстане открыли завод по выпуску материнс...      0\n",
              "\n",
              "[3198 rows x 2 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].apply(spacy_tokenizer)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNUIf2wtiXjP",
        "outputId": "9d3cb4fc-d750-4157-deb3-a062f02c1c77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 3198\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7MzriXSwklRE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tPhbMJ21kzr-"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Ul1t8e0Lk6_v",
        "outputId": "617eb3a7-a50e-4de4-d0ce-b0e455950019"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3198/3198 [00:00<00:00, 39647.27 examples/s]\n"
          ]
        }
      ],
      "source": [
        "tokenized_df = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WcIHrDu2fmHh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 4.20kB [00:00, 7.64MB/s]\n",
            "Downloading builder script: 7.56kB [00:00, 4.94MB/s]\n",
            "Downloading builder script: 6.79kB [00:00, 16.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "metric_f1 = evaluate.load(\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aa-xY_YIf98-"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    d = {\n",
        "        **accuracy.compute(predictions=predictions, references=labels),\n",
        "        **precision.compute(predictions=predictions, references=labels),\n",
        "        **metric_f1.compute(predictions=predictions, references=labels)\n",
        "    }\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Wy3tUdGYhFUB"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"не кликбейт\", 1: \"кликбейт\"}\n",
        "label2id = {\"не кликбейт\": 0, \"кликбейт\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHwRRx8RhSnK",
        "outputId": "3dd26388-9908-4701-b8a5-0dd9c2733481"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"cointegrated/rubert-tiny2\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxE_XwH_hXx0",
        "outputId": "f8ded3d7-756b-49b4-a0c7-26c6299c9e92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 2558\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 640\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = tokenized_df.train_test_split(test_size = 0.2)\n",
        "split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "17SjB7jXjNQd"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "jdOTvlWkj7fP",
        "outputId": "52293862-eab5-4b14-a881-304e6ebb91be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 01:17, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678500</td>\n",
              "      <td>0.454238</td>\n",
              "      <td>0.848437</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.855869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.276300</td>\n",
              "      <td>0.250856</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.929766</td>\n",
              "      <td>0.896774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.171300</td>\n",
              "      <td>0.241735</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.936455</td>\n",
              "      <td>0.903226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.116900</td>\n",
              "      <td>0.245945</td>\n",
              "      <td>0.917188</td>\n",
              "      <td>0.913580</td>\n",
              "      <td>0.917829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.098500</td>\n",
              "      <td>0.253638</td>\n",
              "      <td>0.914062</td>\n",
              "      <td>0.920886</td>\n",
              "      <td>0.913658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=0.26426276326179504, metrics={'train_runtime': 77.9527, 'train_samples_per_second': 164.074, 'train_steps_per_second': 5.131, 'total_flos': 3834904487976.0, 'train_loss': 0.26426276326179504, 'epoch': 5.0})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    remove_unused_columns=True,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=split['train'],\n",
        "    eval_dataset=split['test'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "xtTRn3OclYNH",
        "outputId": "76cf888e-2ab1-4c51-9855-682a673e4b4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.24173521995544434,\n",
              " 'eval_accuracy': 0.90625,\n",
              " 'eval_precision': 0.9364548494983278,\n",
              " 'eval_f1': 0.9032258064516129,\n",
              " 'eval_runtime': 0.4939,\n",
              " 'eval_samples_per_second': 1295.88,\n",
              " 'eval_steps_per_second': 40.496,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(split['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NSuWRgPnF9D",
        "outputId": "be07bbc4-2842-4b1f-a037-da00ee1a9c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              titles  target\n",
            "0  Фракция Порошенко запустила процедуру отставки...     NaN\n",
            "1  Установленное при участии Трампа мирное соглаш...     NaN\n",
            "2         Баффет написал последнее письмо акционерам     NaN\n",
            "3  Нефтегазовые гиганты в кризисе. Почему бум ИИ ...     NaN\n",
            "4  Клишас не исключил существование мошеннической...     NaN\n"
          ]
        }
      ],
      "source": [
        "news_titles = pd.read_csv('C:/Users/slesa/Downloads/news_titles_test.csv', encoding='windows-1251', delimiter=';')\n",
        "print(news_titles.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eZVLfGGrR0L",
        "outputId": "d3a6c8b9-7a56-40de-9af0-02eaec932c72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Фракция Порошенко запустила процедуру отставки правительства Украины',\n",
              " 'Установленное при участии Трампа мирное соглашение оказалось под угрозой',\n",
              " 'Баффет написал последнее письмо акционерам',\n",
              " 'Нефтегазовые гиганты в кризисе. Почему бум ИИ проходит мимо них',\n",
              " 'Клишас не исключил существование мошеннической схемы с продажей жилья',\n",
              " 'Саркози вышел на свободу. Первые кадры после освобождения',\n",
              " 'Как запрет многократных шенгенских виз повлияет на поездки в ЕС',\n",
              " 'Что может принести наибольшую доходность до конца года: топ-6 активов',\n",
              " 'Сколько нужно зарабатывать для большой пенсии в России: расчеты',\n",
              " 'Курс доллара ЦБ на 11 ноября снизился почти до ?81',\n",
              " 'ЦБ назвал самый доходный актив в России с начала года',\n",
              " 'Супругов из Майами признали самой долгоживущей парой в браке',\n",
              " 'Два аэропорта ввели временные ограничения на полеты',\n",
              " '«Баланс» и «право на ошибку»: что известно о новой стратегии «Ростеха»',\n",
              " 'Литва повторно попросит Белоруссию открыть коридор для застрявших фур',\n",
              " 'В Белоруссии временно запретили продажу российских маршмеллоу',\n",
              " 'США частично сняли санкции с Сирии',\n",
              " 'Как сохранить безопасность данных в цифровой среде',\n",
              " '«Дом.РФ» сообщил о восстановлении спроса на новостройки',\n",
              " 'Виновник взрыва в Куркино заявил, что забыл о газе и закурил',\n",
              " 'Абстракционизм: как искусство «отщепенцев» изменило понимание красоты',\n",
              " 'Минцифры назвало два случая «охлаждения» сим-карты',\n",
              " 'Россияне купили максимальный за два года объем валюты',\n",
              " 'В Госдуме опровергли планы отключения России от внешнего интернета',\n",
              " 'Глава Минпромторга посетил стенд ГК «Полипласт» на выставке «Химия-2025»',\n",
              " 'Губернатор объяснил ситуацию с два дня ждавшим захода в порт Сочи паромом',\n",
              " 'С каких иномарок пересаживаются на «китайцев». Отзывы водителей',\n",
              " 'Чем опасна временная регистрация для собственника: 5 последствий',\n",
              " 'Криптовалюта и новая статья КоАП: чем грозят майнинг и p2p-операции',\n",
              " 'Выход из ООО: три сценария, чтобы не потерять деньги']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = []\n",
        "\n",
        "for i in range(len(news_titles['titles'])):\n",
        "  test.append(news_titles['titles'][i])\n",
        "\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ees9qsXHlT9u",
        "outputId": "8a7fd254-23cd-4ffc-f4f3-e8bee89fb5d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'не кликбейт', 'score': 0.9767279028892517},\n",
              " {'label': 'не кликбейт', 'score': 0.9288146495819092},\n",
              " {'label': 'не кликбейт', 'score': 0.93513023853302},\n",
              " {'label': 'не кликбейт', 'score': 0.9472692012786865},\n",
              " {'label': 'не кликбейт', 'score': 0.9586208462715149},\n",
              " {'label': 'не кликбейт', 'score': 0.6323631405830383},\n",
              " {'label': 'не кликбейт', 'score': 0.9199606776237488},\n",
              " {'label': 'кликбейт', 'score': 0.9336825013160706},\n",
              " {'label': 'кликбейт', 'score': 0.98479825258255},\n",
              " {'label': 'не кликбейт', 'score': 0.9400477409362793},\n",
              " {'label': 'не кликбейт', 'score': 0.7816800475120544},\n",
              " {'label': 'не кликбейт', 'score': 0.7360971570014954},\n",
              " {'label': 'не кликбейт', 'score': 0.9794700741767883},\n",
              " {'label': 'кликбейт', 'score': 0.9661126136779785},\n",
              " {'label': 'не кликбейт', 'score': 0.9467094540596008},\n",
              " {'label': 'не кликбейт', 'score': 0.9799922108650208},\n",
              " {'label': 'не кликбейт', 'score': 0.959179162979126},\n",
              " {'label': 'кликбейт', 'score': 0.5061095356941223},\n",
              " {'label': 'кликбейт', 'score': 0.6114882826805115},\n",
              " {'label': 'не кликбейт', 'score': 0.890773355960846},\n",
              " {'label': 'кликбейт', 'score': 0.5149995684623718},\n",
              " {'label': 'не кликбейт', 'score': 0.8966504335403442},\n",
              " {'label': 'не кликбейт', 'score': 0.6135522723197937},\n",
              " {'label': 'не кликбейт', 'score': 0.9797032475471497},\n",
              " {'label': 'не кликбейт', 'score': 0.9781173467636108},\n",
              " {'label': 'не кликбейт', 'score': 0.9701462388038635},\n",
              " {'label': 'кликбейт', 'score': 0.9054228663444519},\n",
              " {'label': 'кликбейт', 'score': 0.9790917038917542},\n",
              " {'label': 'не кликбейт', 'score': 0.9128063321113586},\n",
              " {'label': 'кликбейт', 'score': 0.9720345735549927}]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=trainer.model.cpu(), tokenizer=tokenizer)\n",
        "classifier(test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
